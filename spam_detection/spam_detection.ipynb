{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library and open the data sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, I am only opening files from the enron1 and enron2 folders due to the RAM limitations of the device I am using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "from tqdm import tqdm\n",
    "\n",
    "X, y = [], []\n",
    "for i in tqdm(range(1,3)):\n",
    "    emails = load_files(f\"enron{i}\")\n",
    "    X = np.append(X, emails.data)\n",
    "    y = np.append(y, emails.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the data frame as 'df' with two columns, 'text' and 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['text', 'target'])\n",
    "df['text'] = [x for x in X]\n",
    "df['target'] = [t for t in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Subject: nesa / hea \\' s 24 th annual meetin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Subject: meter 1431 - nov 1999\\r\\ndaren -\\r\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"Subject: investor here .\\r\\nfrom : mr . rich...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Subject: hi paliourg all available meds . av...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'Subject: january nominations at shell deer p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11024</th>\n",
       "      <td>b'Subject: investment / partnership proposal\\r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11025</th>\n",
       "      <td>b'Subject: re : fwd : praca dyplomowa v edycja...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11026</th>\n",
       "      <td>b'Subject: fw : citi , wells , enron , sl and ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027</th>\n",
       "      <td>b'Subject: re : subscription renewal\\r\\nstepha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>b\"Subject: re : update - meteorologist search\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11029 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      b'Subject: nesa / hea \\' s 24 th annual meetin...     0.0\n",
       "1      b'Subject: meter 1431 - nov 1999\\r\\ndaren -\\r\\...     0.0\n",
       "2      b\"Subject: investor here .\\r\\nfrom : mr . rich...     1.0\n",
       "3      b\"Subject: hi paliourg all available meds . av...     1.0\n",
       "4      b'Subject: january nominations at shell deer p...     0.0\n",
       "...                                                  ...     ...\n",
       "11024  b'Subject: investment / partnership proposal\\r...     1.0\n",
       "11025  b'Subject: re : fwd : praca dyplomowa v edycja...     0.0\n",
       "11026  b'Subject: fw : citi , wells , enron , sl and ...     0.0\n",
       "11027  b'Subject: re : subscription renewal\\r\\nstepha...     0.0\n",
       "11028  b\"Subject: re : update - meteorologist search\\...     0.0\n",
       "\n",
       "[11029 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import library for data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define function for cleansing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text):\n",
    "    # Make sentence being lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Decode bytes to string\n",
    "    text = text.decode('latin-1')\n",
    "\n",
    "    # Remove hashtag\n",
    "    pattern_3 = r'#([^\\s]+)'\n",
    "    text = re.sub(pattern_3, '', text)\n",
    "\n",
    "    # Remove general punctuation, math operation char, etc.\n",
    "    pattern_4 = r'[\\,\\@\\*\\_\\-\\!\\:\\;\\?\\'\\.\\\"\\)\\(\\{\\}\\<\\>\\+\\%\\$\\^\\#\\/\\`\\~\\|\\&\\|]'\n",
    "    text = re.sub(pattern_4, ' ', text)\n",
    "\n",
    "    # Remove emoji\n",
    "    pattern_6 = r'\\\\[a-z0-9]{1,5}'\n",
    "    text = re.sub(pattern_6, '', text)\n",
    "\n",
    "    # Remove (\\); ([); (])\n",
    "    pattern_9 = r'[\\\\\\]\\[]'\n",
    "    text = re.sub(pattern_9, '', text)\n",
    "\n",
    "    # Remove character non ASCII\n",
    "    pattern_10 = r'[^\\x00-\\x7f]'\n",
    "    text = re.sub(pattern_10, '', text)\n",
    "\n",
    "    # Remove character non ASCII\n",
    "    pattern_11 = r'(\\\\u[0-9A-Fa-f]+)'\n",
    "    text = re.sub(pattern_11, '', text)\n",
    "\n",
    "    # Remove multiple whitespace\n",
    "    pattern_12 = r'(\\s+|\\\\n)'\n",
    "    text = re.sub(pattern_12, ' ', text)\n",
    "    \n",
    "    # Remove whitespace at the first and end sentences\n",
    "    text = text.rstrip()\n",
    "    text = text.lstrip()\n",
    "    return text\n",
    "\n",
    "def tokenisasi(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split data frame, 'df_X' contains 'text', and 'df_y' contains 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.drop(['target'], axis=1)\n",
    "df_y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 11029 entries, 0 to 11028\n",
      "Series name: text\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "11029 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 86.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df['text'].info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply cleansing function for data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject nesa hea s 24 th annual meeting saddle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject meter 1431 nov 1999 daren could you pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject investor here from mr richard mayer de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject hi paliourg all available meds availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject january nominations at shell deer park...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11024</th>\n",
       "      <td>subject investment partnership proposal dear s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11025</th>\n",
       "      <td>subject re fwd praca dyplomowa v edycja mba wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11026</th>\n",
       "      <td>subject fw citi wells enron sl and i 2 form a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027</th>\n",
       "      <td>subject re subscription renewal stephanie than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>subject re update meteorologist search great w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11029 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      subject nesa hea s 24 th annual meeting saddle...\n",
       "1      subject meter 1431 nov 1999 daren could you pl...\n",
       "2      subject investor here from mr richard mayer de...\n",
       "3      subject hi paliourg all available meds availab...\n",
       "4      subject january nominations at shell deer park...\n",
       "...                                                  ...\n",
       "11024  subject investment partnership proposal dear s...\n",
       "11025  subject re fwd praca dyplomowa v edycja mba wa...\n",
       "11026  subject fw citi wells enron sl and i 2 form a ...\n",
       "11027  subject re subscription renewal stephanie than...\n",
       "11028  subject re update meteorologist search great w...\n",
       "\n",
       "[11029 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X['text'] = df_X['text'].apply(cleansing)\n",
    "df_X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. In the modeling stage, I used the Neural Network algorithm (Long Short Term Memory) from the keras library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I performed tokenization using the help of the keras library and limited the number of words tokenized to 50000, and the sequence length to 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73237 unique tokens.\n",
      "Shape of Data Tensor :  (11029, 250)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "sentences = df_X['text'].to_list()\n",
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(sentences)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of Data Tensor : ', X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I created a new column for each unique value in the label column, and filled it with 0 or 1. Then, the .values method was used to retrieve the values from the processed DataFrame and convert them into a numpy array. The final result is a tensor containing labels in the form of one hot encoding (0 or 1), so that it can be processed by Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Label Tensor :  (11029, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df_y).values\n",
    "print('Shape of Label Tensor : ', Y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I used the help of the sklearn library to split the data into 'train' and 'test'. The train data is 80%, and the test data is 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8823, 250) (8823, 2)\n",
      "(2206, 250) (2206, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I will implement a model to perform classification on 'train' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "111/111 [==============================] - 118s 1s/step - loss: 0.2742 - accuracy: 0.8722 - val_loss: 0.0638 - val_accuracy: 0.9802\n",
      "Epoch 2/2\n",
      "111/111 [==============================] - 110s 991ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.0708 - val_accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an explanation of the code above:\n",
    "\n",
    "* The first and second lines import the necessary modules to create and train a neural network model in Keras.\n",
    "* The third line creates a Sequential object, which is used to add layers to the neural network model in sequence.\n",
    "* The fourth line adds an Embedding layer to the model, which is used to convert each word in the document into a numeric vector with the same dimension. MAX_NB_WORDS and EMBEDDING_DIM are parameters used to adjust the size of the embedding layer.\n",
    "* The fifth line adds a SpatialDropout1D layer, which is used to reduce overfitting in the model.\n",
    "* The sixth line adds an LSTM layer, which is a type of recurrent layer in neural networks used to process sequential data such as text.\n",
    "* The seventh line adds a Dense layer with softmax activation to the model, which is used to perform classification on text data into two categories (in this case, positive and negative).\n",
    "* The eighth line compiles the model using categorical_crossentropy loss function, adam optimizer, and accuracy metrics.\n",
    "* The ninth and tenth lines train the model using X_train and Y_train as input and output data. epochs and batch_size are parameters used to adjust the number of iterations and batch size during model training.\n",
    "* The last line saves the training results of the model in the history object."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Making predictions on the 'test' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 6s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2206, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "accuracy = accuracy_score(Y_test_classes, y_pred_classes)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1622\n",
      "           1       0.91      0.99      0.95       584\n",
      "\n",
      "    accuracy                           0.97      2206\n",
      "   macro avg       0.95      0.98      0.96      2206\n",
      "weighted avg       0.97      0.97      0.97      2206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(Y_test_classes, y_pred_classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, I obtained the accuracy of the applied model to the data. I obtained an accuracy of 97%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"email_spam_classifier.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Testing on different data, namely files from the 'enron4' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 16s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import load_model\n",
    "\n",
    "X, y = [], []\n",
    "for i in tqdm(range(4,5)):\n",
    "    emails = load_files(f\"enron{i}\")\n",
    "    X = np.append(X, emails.data)\n",
    "    y = np.append(y, emails.target)\n",
    "\n",
    "df_new = pd.DataFrame(columns=['text', 'target'])\n",
    "df_new['text'] = [x for x in X]\n",
    "df_new['target'] = [t for t in y]\n",
    "\n",
    "df_X = df_new.drop(['target'], axis=1)\n",
    "df_y = df_new['target']\n",
    "\n",
    "df_X['text'] = df_X['text'].apply(cleansing)\n",
    "\n",
    "sentences = df_X['text'].to_list()\n",
    "\n",
    "# lakukan preprocessing pada data baru\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "X_new = tokenizer.texts_to_sequences(sentences)\n",
    "X_new = pad_sequences(X_new, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "loaded_model = load_model(\"email_spam_classifier.h5\")\n",
    "\n",
    "# lakukan prediksi pada data baru\n",
    "y_prob = loaded_model.predict(X_new)\n",
    "y_pred = y_prob.argmax(axis=-1)\n",
    "\n",
    "# konversi nilai prediksi menjadi label sentimen\n",
    "labels = {0: \"spam\", 1: \"ham\"}\n",
    "df_X['target'] = [labels[pred] for pred in y_pred]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Viewing the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject are you infected with spyware is your ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject turn 500 into 1200 day starting today ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject mystery shopping extra casual income c...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject re kathy from epe s answer amy that s ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject start date 1 27 02 hourahead hour 5 st...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>subject your pharmacy fk do you want a cheap p...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>subject 51 mortgage rates as low as 3 99 g day...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>subject fw upto 80 off on prescrlpt 1 on drogs...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>subject huge oem soft discounts here 75 pyroxe...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>subject hi fda approved drugsno prior prescrii...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target\n",
       "0     subject are you infected with spyware is your ...   spam\n",
       "1     subject turn 500 into 1200 day starting today ...   spam\n",
       "2     subject mystery shopping extra casual income c...   spam\n",
       "3     subject re kathy from epe s answer amy that s ...   spam\n",
       "4     subject start date 1 27 02 hourahead hour 5 st...   spam\n",
       "...                                                 ...    ...\n",
       "5994  subject your pharmacy fk do you want a cheap p...   spam\n",
       "5995  subject 51 mortgage rates as low as 3 99 g day...   spam\n",
       "5996  subject fw upto 80 off on prescrlpt 1 on drogs...   spam\n",
       "5997  subject huge oem soft discounts here 75 pyroxe...    ham\n",
       "5998  subject hi fda approved drugsno prior prescrii...   spam\n",
       "\n",
       "[5999 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject are you infected with spyware is your ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject turn 500 into 1200 day starting today ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject mystery shopping extra casual income c...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject re kathy from epe s answer amy that s ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject start date 1 27 02 hourahead hour 5 st...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>subject pay les for microsoft office software ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>subject your pharmacy fk do you want a cheap p...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>subject 51 mortgage rates as low as 3 99 g day...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>subject fw upto 80 off on prescrlpt 1 on drogs...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>subject hi fda approved drugsno prior prescrii...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4766 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target\n",
       "0     subject are you infected with spyware is your ...   spam\n",
       "1     subject turn 500 into 1200 day starting today ...   spam\n",
       "2     subject mystery shopping extra casual income c...   spam\n",
       "3     subject re kathy from epe s answer amy that s ...   spam\n",
       "4     subject start date 1 27 02 hourahead hour 5 st...   spam\n",
       "...                                                 ...    ...\n",
       "5993  subject pay les for microsoft office software ...   spam\n",
       "5994  subject your pharmacy fk do you want a cheap p...   spam\n",
       "5995  subject 51 mortgage rates as low as 3 99 g day...   spam\n",
       "5996  subject fw upto 80 off on prescrlpt 1 on drogs...   spam\n",
       "5998  subject hi fda approved drugsno prior prescrii...   spam\n",
       "\n",
       "[4766 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.loc[df_X['target'].str.contains('spam')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>subject you need this jkoutsi look at this of ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>subject</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>subject borax craig paliourg valiumxanaxcialis...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>subject personals do you know what i want good...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>subject paliourg iit demokritos gr culpable re...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>subject medications at huge discounts valium a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>subject azalea goodyear biography faro reject ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>subject hey check it out hi i just saw somethi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>subject re average girly ejaculation movies da...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>subject huge oem soft discounts here 75 pyroxe...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target\n",
       "6     subject you need this jkoutsi look at this of ...    ham\n",
       "17                                              subject    ham\n",
       "20    subject borax craig paliourg valiumxanaxcialis...    ham\n",
       "21    subject personals do you know what i want good...    ham\n",
       "22    subject paliourg iit demokritos gr culpable re...    ham\n",
       "...                                                 ...    ...\n",
       "5975  subject medications at huge discounts valium a...    ham\n",
       "5983  subject azalea goodyear biography faro reject ...    ham\n",
       "5984  subject hey check it out hi i just saw somethi...    ham\n",
       "5987  subject re average girly ejaculation movies da...    ham\n",
       "5997  subject huge oem soft discounts here 75 pyroxe...    ham\n",
       "\n",
       "[1233 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.loc[df_X['target'].str.contains('ham')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files in the 'enron4' folder contain 1555 emails categorized as 'ham (not spam)', and 4444 emails categorized as 'spam'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c28da407b5413b3940d87ecdae5ea8ce0c2929d84f560e9f5daaaa2573d53e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
